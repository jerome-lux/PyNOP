{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b36126e-68e9-4714-9363-2427cc4b3099",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0339afcf-5a91-411c-8412-dfea5191b37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "import math\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "import datetime\n",
    "import json\n",
    "from PIL import Image\n",
    "from attr import dataclass\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor, optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingLR\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, Subset\n",
    "from torchvision.transforms import v2\n",
    "from torchinfo import summary\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor, EarlyStopping, TQDMProgressBar\n",
    "from pytorch_lightning.loggers import CSVLogger, TensorBoardLogger\n",
    "\n",
    "import pynop\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43077fe6",
   "metadata": {},
   "source": [
    "# Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9b2e511",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pynop.LITNet(\n",
    "    in_channels=2,\n",
    "    out_channels=2,\n",
    "    modes=16,\n",
    "    hidden_channels=[48, 48, 48, 48, 48],\n",
    "    block=partial(pynop.ITBlock, compute_ortho_loss=True, sampling=int(64*64)),\n",
    "    mlp_layers=2,\n",
    "    mlp_dim=64,\n",
    "    activation=nn.GELU,\n",
    "    norm=pynop.LayerNorm2d,\n",
    "    fixed_pos_encoding=True,\n",
    ").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21dd00b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "LITNet                                        [1, 2, 128, 128]          --\n",
       "├─CartesianEmbedding: 1-1                     [1, 4, 128, 128]          --\n",
       "├─Conv2d: 1-2                                 [1, 48, 128, 128]         240\n",
       "├─ModuleList: 1-3                             --                        --\n",
       "│    └─ITBlock: 2-1                           [1, 48, 128, 128]         589,824\n",
       "│    │    └─ComplexMLPBlock: 3-1              [16384, 256]              40,960\n",
       "│    │    └─Conv2d: 3-2                       [1, 48, 128, 128]         2,352\n",
       "│    │    └─LayerNorm2d: 3-3                  [1, 48, 128, 128]         96\n",
       "│    │    └─GELU: 3-4                         [1, 48, 128, 128]         --\n",
       "│    │    └─Conv2d: 3-5                       [1, 48, 128, 128]         2,352\n",
       "│    │    └─GELU: 3-6                         [1, 48, 128, 128]         --\n",
       "│    └─ITBlock: 2-2                           [1, 48, 128, 128]         589,824\n",
       "│    │    └─ComplexMLPBlock: 3-7              [16384, 256]              40,960\n",
       "│    │    └─Conv2d: 3-8                       [1, 48, 128, 128]         2,352\n",
       "│    │    └─LayerNorm2d: 3-9                  [1, 48, 128, 128]         96\n",
       "│    │    └─GELU: 3-10                        [1, 48, 128, 128]         --\n",
       "│    │    └─Conv2d: 3-11                      [1, 48, 128, 128]         2,352\n",
       "│    │    └─GELU: 3-12                        [1, 48, 128, 128]         --\n",
       "│    └─ITBlock: 2-3                           [1, 48, 128, 128]         589,824\n",
       "│    │    └─ComplexMLPBlock: 3-13             [16384, 256]              40,960\n",
       "│    │    └─Conv2d: 3-14                      [1, 48, 128, 128]         2,352\n",
       "│    │    └─LayerNorm2d: 3-15                 [1, 48, 128, 128]         96\n",
       "│    │    └─GELU: 3-16                        [1, 48, 128, 128]         --\n",
       "│    │    └─Conv2d: 3-17                      [1, 48, 128, 128]         2,352\n",
       "│    │    └─GELU: 3-18                        [1, 48, 128, 128]         --\n",
       "│    └─ITBlock: 2-4                           [1, 48, 128, 128]         589,824\n",
       "│    │    └─ComplexMLPBlock: 3-19             [16384, 256]              40,960\n",
       "│    │    └─Conv2d: 3-20                      [1, 48, 128, 128]         2,352\n",
       "│    │    └─LayerNorm2d: 3-21                 [1, 48, 128, 128]         96\n",
       "│    │    └─GELU: 3-22                        [1, 48, 128, 128]         --\n",
       "│    │    └─Conv2d: 3-23                      [1, 48, 128, 128]         2,352\n",
       "│    │    └─GELU: 3-24                        [1, 48, 128, 128]         --\n",
       "│    └─ITBlock: 2-5                           [1, 48, 128, 128]         589,824\n",
       "│    │    └─ComplexMLPBlock: 3-25             [16384, 256]              40,960\n",
       "│    │    └─Conv2d: 3-26                      [1, 48, 128, 128]         2,352\n",
       "│    │    └─LayerNorm2d: 3-27                 [1, 48, 128, 128]         96\n",
       "│    │    └─GELU: 3-28                        [1, 48, 128, 128]         --\n",
       "│    │    └─Conv2d: 3-29                      [1, 48, 128, 128]         2,352\n",
       "│    │    └─GELU: 3-30                        [1, 48, 128, 128]         --\n",
       "├─Conv2d: 1-4                                 [1, 2, 128, 128]          98\n",
       "===============================================================================================\n",
       "Total params: 3,178,258\n",
       "Trainable params: 3,178,258\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 3.75\n",
       "===============================================================================================\n",
       "Input size (MB): 0.13\n",
       "Forward/backward pass size (MB): 604.24\n",
       "Params size (MB): 0.92\n",
       "Estimated Total Size (MB): 605.29\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, input_size=(1,2,128,128))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d00cdb",
   "metadata": {},
   "source": [
    "# Data loading, creation of the train/val sets and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "522c977b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning train: 100%|██████████| 800/800 [00:04<00:00, 195.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split train: 800 simulations\n",
      "Total unrolled windows: 8000\n",
      "Status: All data loaded in RAM.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning val: 100%|██████████| 200/200 [00:00<00:00, 205.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split val: 200 simulations\n",
      "Total unrolled windows: 2000\n",
      "Status: All data loaded in RAM.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# datapath = Path(\"F:/Projets/2D_diff-react_NA_NA.h5\")\n",
    "datapath = Path(\"/media/jlux/SSD2/pdebench/2d_reaction_diffusion/133017.hdf5\")\n",
    "train_set = pynop.UnrolledH5Dataset(\n",
    "    datapath, T_unroll=10, step=10, load_in_ram=True, split_type=\"train\", split_ratio=0.8, seed=42\n",
    ")\n",
    "val_set = pynop.UnrolledH5Dataset(\n",
    "    datapath, T_unroll=10, step=10, load_in_ram=True, split_type=\"val\", split_ratio=0.8, seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b631d1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 6\n",
    "train_dataloader = DataLoader(train_set, shuffle=True, batch_size=batch_size, num_workers=10)\n",
    "valid_dataloader = DataLoader(\n",
    "    val_set, shuffle=False, batch_size=batch_size, num_workers=10, persistent_workers=True, pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41985f12",
   "metadata": {},
   "source": [
    "# Preparing the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27ce6982",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log dir: /media/jlux/SSD2/ReactionDiffusion/NLIT/20260113-174819\n"
     ]
    }
   ],
   "source": [
    "# baselogdir = Path(\"F:/Projets/NLIT\")\n",
    "baselogdir = Path(\"/media/jlux/SSD2/ReactionDiffusion/NLIT\")\n",
    "\n",
    "now = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "logdir = Path(baselogdir / f\"{now}\")\n",
    "callbacks = []\n",
    "\n",
    "loggers = [TensorBoardLogger(logdir / Path(\"tb_logs\"), name=\"NLIT_RD\"), CSVLogger(logdir, name=\"NLIT_RD\")]\n",
    "\n",
    "callbacks.append(\n",
    "    ModelCheckpoint(\n",
    "        monitor=\"val_loss\", filename=os.path.join(logdir, \"best_val_loss\"), mode=\"min\", save_top_k=2, save_last=False\n",
    "    )\n",
    ")\n",
    "\n",
    "callbacks.append(\n",
    "    ModelCheckpoint(\n",
    "        monitor=\"loss\",\n",
    "        filename=os.path.join(logdir, \"best_train_loss\"),\n",
    "        mode=\"min\",\n",
    "        save_top_k=2,\n",
    "        save_last=False,\n",
    "    )\n",
    ")\n",
    "\n",
    "callbacks.append(LearningRateMonitor(logging_interval=\"epoch\"))\n",
    "# callbacks.append(EarlyStopping(monitor=\"val_loss\", min_delta=0.00, patience=10, verbose=False, mode=\"min\"))\n",
    "\n",
    "\n",
    "# print values in scientific format\n",
    "class CustomProgressBar(TQDMProgressBar):\n",
    "    def get_metrics(self, trainer, model):\n",
    "        items = super().get_metrics(trainer, model)\n",
    "        # On applique le format scientifique à tout le dictionnaire\n",
    "        return {k: (f\"{v:.3e}\" if isinstance(v, float) else v) for k, v in items.items()}\n",
    "\n",
    "\n",
    "# callbacks.append(TQDMProgressBar(leave=True))\n",
    "callbacks.append(CustomProgressBar(leave=True))\n",
    "\n",
    "train_config = pynop.TrainingSchedule(\n",
    "    start_autoregressive=0,\n",
    "    final_autoregressive=100,\n",
    "    min_autoregressive_steps=4,\n",
    "    max_autoregressive_steps=8,\n",
    "    detach_grad_steps=8,\n",
    "    loss_fn=torch.nn.MSELoss(),\n",
    "    force_orthogonality=True,\n",
    "    ortho_weight=1,\n",
    "    noise_level=5e-4,\n",
    ")\n",
    "\n",
    "max_epochs = 100\n",
    "lr = 8e-4\n",
    "\n",
    "scheduler_config = [\n",
    "    {\n",
    "        \"scheduler\": ReduceLROnPlateau,\n",
    "        \"mode\": \"min\",\n",
    "        \"patience\": 10,\n",
    "        \"factor\": 0.5,\n",
    "        \"monitor\": \"MSE\",\n",
    "        \"interval\": \"epoch\",\n",
    "        \"frequency\": 1,\n",
    "        \"cooldown\": 0,\n",
    "    },\n",
    "]\n",
    "\n",
    "# scheduler_config = [\n",
    "#     {\n",
    "#         \"scheduler\": CosineAnnealingLR,\n",
    "#         \"T_max\": max_epochs * int(len(train_set) / batch_size),\n",
    "#         \"eta_min\":lr*1e-2,\n",
    "#         \"interval\": \"step\",\n",
    "#         \"frequency\": 1,\n",
    "#     },\n",
    "# ]\n",
    "\n",
    "optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=lr, weight_decay=1e-5)\n",
    "\n",
    "# From scratch\n",
    "lightning_model = pynop.Model(\n",
    "    model=model, train_config=train_config, optimizer=optimizer, scheduler_config=scheduler_config\n",
    ")\n",
    "# checkpoint = torch.load(Path(\"/media/jlux/SSD2/ReactionDiffusion/NLIT/20260111-145353/best_train_loss.ckpt\"))\n",
    "# lightning_model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "# torch.set_float32_matmul_precision('highest')\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=max_epochs,\n",
    "    limit_train_batches=0.34,\n",
    "    callbacks=callbacks,\n",
    "    accelerator=\"gpu\",\n",
    "    logger=loggers,\n",
    "    num_sanity_val_steps=1,\n",
    ")\n",
    "# gradient_clip_val=1,\n",
    "# gradient_clip_algorithm=\"norm\")\n",
    "\n",
    "print(\"Log dir:\", logdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2ecb67",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b788d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type       | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model          | LITNet     | 3.2 M  | train\n",
      "1 | loss_fn        | MSELoss    | 0      | train\n",
      "2 | train_loss_avg | MeanMetric | 0      | train\n",
      "------------------------------------------------------\n",
      "3.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.2 M     Total params\n",
      "12.713    Total estimated model params size (MB)\n",
      "77        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a39abf6cdc6c43d8b58a0e54ac5c40ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e891704559184b3d8917e59855f1421c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5b13446c48e4deab56f2401e4cedeb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13f6862ce19845d08fa98842ac45e5c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35dbb18a059b497a9d7bb3d867ed6433",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "922b0563180346d698b9dfa5d512316e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "942c15d4c9004cf0bacbc0581100148e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(lightning_model, train_dataloaders=train_dataloader, val_dataloaders=valid_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728e286f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
