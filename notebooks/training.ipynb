{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b36126e-68e9-4714-9363-2427cc4b3099",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0339afcf-5a91-411c-8412-dfea5191b37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "import math\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "import datetime\n",
    "import json\n",
    "import collections.abc as abc\n",
    "from PIL import Image\n",
    "from attr import dataclass\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor, optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingLR\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, Subset\n",
    "from torchvision.transforms import v2\n",
    "from torchinfo import summary\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor, EarlyStopping, TQDMProgressBar\n",
    "from pytorch_lightning.loggers import CSVLogger, TensorBoardLogger\n",
    "\n",
    "import pynop\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43077fe6",
   "metadata": {},
   "source": [
    "# Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9b2e511",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pynop.LITNet(\n",
    "    in_channels=2,\n",
    "    out_channels=2,\n",
    "    modes=16,\n",
    "    hidden_channels=[48, 48, 48, 48, 48],\n",
    "    block=pynop.NLITBlock,\n",
    "    mlp_layers=2,\n",
    "    mlp_dim=64,\n",
    "    activation=nn.GELU,\n",
    "    norm=pynop.LayerNorm2d,\n",
    "    fixed_pos_encoding=True,\n",
    "    trainable_pos_encoding=True,\n",
    "    trainable_pos_encoding_dims=8,\n",
    ").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21dd00b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "LITNet                                        [1, 2, 128, 128]          2,048\n",
       "├─CartesianEmbedding: 1-1                     [1, 4, 128, 128]          --\n",
       "├─LITDecoder: 1-2                             [1, 8, 128, 128]          16,384\n",
       "│    └─MLPBlock: 2-1                          [16384, 256]              --\n",
       "│    │    └─Sequential: 3-1                   [16384, 512]              37,888\n",
       "│    └─Conv2d: 2-2                            [1, 8, 128, 128]          72\n",
       "│    └─LayerNorm2d: 2-3                       [1, 8, 128, 128]          16\n",
       "│    └─GELU: 2-4                              [1, 8, 128, 128]          --\n",
       "├─Conv2d: 1-3                                 [1, 48, 128, 128]         624\n",
       "├─ModuleList: 1-4                             --                        --\n",
       "│    └─NLITBlock: 2-5                         [1, 48, 128, 128]         589,824\n",
       "│    │    └─MLPBlock: 3-2                     [16384, 256]              40,960\n",
       "│    │    └─Conv2d: 3-3                       [1, 48, 128, 128]         2,352\n",
       "│    │    └─LayerNorm2d: 3-4                  [1, 48, 128, 128]         96\n",
       "│    │    └─GELU: 3-5                         [1, 48, 128, 128]         --\n",
       "│    │    └─Conv2d: 3-6                       [1, 48, 128, 128]         2,352\n",
       "│    │    └─GELU: 3-7                         [1, 48, 128, 128]         --\n",
       "│    └─NLITBlock: 2-6                         [1, 48, 128, 128]         589,824\n",
       "│    │    └─MLPBlock: 3-8                     [16384, 256]              40,960\n",
       "│    │    └─Conv2d: 3-9                       [1, 48, 128, 128]         2,352\n",
       "│    │    └─LayerNorm2d: 3-10                 [1, 48, 128, 128]         96\n",
       "│    │    └─GELU: 3-11                        [1, 48, 128, 128]         --\n",
       "│    │    └─Conv2d: 3-12                      [1, 48, 128, 128]         2,352\n",
       "│    │    └─GELU: 3-13                        [1, 48, 128, 128]         --\n",
       "│    └─NLITBlock: 2-7                         [1, 48, 128, 128]         589,824\n",
       "│    │    └─MLPBlock: 3-14                    [16384, 256]              40,960\n",
       "│    │    └─Conv2d: 3-15                      [1, 48, 128, 128]         2,352\n",
       "│    │    └─LayerNorm2d: 3-16                 [1, 48, 128, 128]         96\n",
       "│    │    └─GELU: 3-17                        [1, 48, 128, 128]         --\n",
       "│    │    └─Conv2d: 3-18                      [1, 48, 128, 128]         2,352\n",
       "│    │    └─GELU: 3-19                        [1, 48, 128, 128]         --\n",
       "│    └─NLITBlock: 2-8                         [1, 48, 128, 128]         589,824\n",
       "│    │    └─MLPBlock: 3-20                    [16384, 256]              40,960\n",
       "│    │    └─Conv2d: 3-21                      [1, 48, 128, 128]         2,352\n",
       "│    │    └─LayerNorm2d: 3-22                 [1, 48, 128, 128]         96\n",
       "│    │    └─GELU: 3-23                        [1, 48, 128, 128]         --\n",
       "│    │    └─Conv2d: 3-24                      [1, 48, 128, 128]         2,352\n",
       "│    │    └─GELU: 3-25                        [1, 48, 128, 128]         --\n",
       "│    └─NLITBlock: 2-9                         [1, 48, 128, 128]         589,824\n",
       "│    │    └─MLPBlock: 3-26                    [16384, 256]              40,960\n",
       "│    │    └─Conv2d: 3-27                      [1, 48, 128, 128]         2,352\n",
       "│    │    └─LayerNorm2d: 3-28                 [1, 48, 128, 128]         96\n",
       "│    │    └─GELU: 3-29                        [1, 48, 128, 128]         --\n",
       "│    │    └─Conv2d: 3-30                      [1, 48, 128, 128]         2,352\n",
       "│    │    └─GELU: 3-31                        [1, 48, 128, 128]         --\n",
       "├─Conv2d: 1-5                                 [1, 2, 128, 128]          98\n",
       "===============================================================================================\n",
       "Total params: 3,235,050\n",
       "Trainable params: 3,235,050\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 4.37\n",
       "===============================================================================================\n",
       "Input size (MB): 0.13\n",
       "Forward/backward pass size (MB): 707.00\n",
       "Params size (MB): 1.07\n",
       "Estimated Total Size (MB): 708.20\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, input_size=(1,2,128,128))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d00cdb",
   "metadata": {},
   "source": [
    "# Data loading, creation of the train/val sets and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "522c977b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Scanning train: 100%|██████████| 800/800 [00:03<00:00, 218.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split train: 800 simulations\n",
      "Total unrolled windows: 8000\n",
      "Status: All data loaded in RAM.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Scanning val: 100%|██████████| 200/200 [00:00<00:00, 222.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split val: 200 simulations\n",
      "Total unrolled windows: 2000\n",
      "Status: All data loaded in RAM.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# datapath = Path(\"F:/Projets/2D_diff-react_NA_NA.h5\")\n",
    "datapath = Path(\"/media/jlux/SSD2/pdebench/2d_reaction_diffusion/133017.hdf5\")\n",
    "train_set = pynop.UnrolledH5Dataset(\n",
    "    datapath, T_unroll=10, step=10, load_in_ram=True, split_type=\"train\", split_ratio=0.8, seed=42\n",
    ")\n",
    "val_set = pynop.UnrolledH5Dataset(\n",
    "    datapath, T_unroll=10, step=10, load_in_ram=True, split_type=\"val\", split_ratio=0.8, seed=42\n",
    ")\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    # Optionnel : permet de s'assurer que chaque worker a une graine aléatoire différente\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "\n",
    "batch_size = 6\n",
    "train_dataloader = DataLoader(train_set, shuffle=True, batch_size=batch_size, num_workers=10)\n",
    "valid_dataloader = DataLoader(\n",
    "    val_set, shuffle=False, batch_size=batch_size, num_workers=10, persistent_workers=True, pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41985f12",
   "metadata": {},
   "source": [
    "# Preparing the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27ce6982",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log dir: /media/jlux/SSD2/NLIT/RD/20260107-181553\n"
     ]
    }
   ],
   "source": [
    "# baselogdir = Path(\"F:/Projets/NLIT\")\n",
    "baselogdir = Path(\"/media/jlux/SSD2/NLIT/RD\")\n",
    "\n",
    "now = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "logdir = Path(baselogdir / f\"{now}\")\n",
    "callbacks = []\n",
    "\n",
    "loggers = [TensorBoardLogger(logdir / Path(\"tb_logs\"), name=\"NLIT_RD\"), CSVLogger(logdir, name=\"NLIT_RD\")]\n",
    "\n",
    "callbacks.append(\n",
    "    ModelCheckpoint(\n",
    "        monitor=\"val_loss\", filename=os.path.join(logdir, \"best_val_loss\"), mode=\"min\", save_top_k=2, save_last=False\n",
    "    )\n",
    ")\n",
    "\n",
    "callbacks.append(\n",
    "    ModelCheckpoint(\n",
    "        monitor=\"loss\",\n",
    "        filename=os.path.join(logdir, \"best_train_loss\"),\n",
    "        mode=\"min\",\n",
    "        save_top_k=2,\n",
    "        save_last=False,\n",
    "    )\n",
    ")\n",
    "\n",
    "callbacks.append(LearningRateMonitor(logging_interval=\"epoch\"))\n",
    "callbacks.append(EarlyStopping(monitor=\"val_loss\", min_delta=0.00, patience=10, verbose=False, mode=\"max\"))\n",
    "\n",
    "# print values in scientific format\n",
    "class CustomProgressBar(TQDMProgressBar):\n",
    "    def get_metrics(self, trainer, model):\n",
    "        items = super().get_metrics(trainer, model)\n",
    "        # On applique le format scientifique à tout le dictionnaire\n",
    "        return {k: (f\"{v:.3e}\" if isinstance(v, float) else v) for k, v in items.items()}\n",
    "\n",
    "# callbacks.append(TQDMProgressBar(leave=True))\n",
    "callbacks.append(CustomProgressBar(leave=True))\n",
    "\n",
    "train_config = pynop.TrainingSchedule(\n",
    "    start_autoregressive=10,\n",
    "    final_autoregressive=110,\n",
    "    max_autoregressive_steps=8,\n",
    "    detach_grad_steps=4,\n",
    "    loss_fn=torch.nn.MSELoss(),\n",
    ")\n",
    "\n",
    "max_epochs = 200\n",
    "lr = 1e-3\n",
    "\n",
    "scheduler_config = [\n",
    "    {\n",
    "        \"scheduler\": ReduceLROnPlateau,\n",
    "        \"mode\": \"min\",\n",
    "        \"patience\": 3,\n",
    "        \"factor\": 0.5,\n",
    "        \"monitor\": \"loss\",\n",
    "        \"interval\": \"epoch\",\n",
    "        \"frequency\": 1,\n",
    "    },\n",
    "]\n",
    "\n",
    "# scheduler_config = [\n",
    "#     {\n",
    "#         \"scheduler\": CosineAnnealingLR,\n",
    "#         \"T_max\": max_epochs * int(len(train_set) / batch_size),\n",
    "#         \"eta_min\":lr*1e-2,\n",
    "#         \"interval\": \"step\",\n",
    "#         \"frequency\": 1,\n",
    "#     },\n",
    "# ]\n",
    "\n",
    "optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-3, weight_decay=5e-3)\n",
    "\n",
    "lightning_model = pynop.Model(\n",
    "    model=model, train_config=train_config, optimizer=optimizer, scheduler_config=scheduler_config\n",
    ")\n",
    "\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=max_epochs,\n",
    "    callbacks=callbacks,\n",
    "    accelerator=\"gpu\",\n",
    "    logger=loggers,\n",
    "    num_sanity_val_steps=1,\n",
    "    # gradient_clip_val=1,\n",
    ")\n",
    "\n",
    "print(\"Log dir:\", logdir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2ecb67",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b788d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | model   | LITNet  | 3.2 M  | eval \n",
      "1 | loss_fn | MSELoss | 0      | train\n",
      "--------------------------------------------\n",
      "3.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.2 M     Total params\n",
      "12.940    Total estimated model params size (MB)\n",
      "1         Modules in train mode\n",
      "88        Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95658cd920ef48e2b6e899f32fd144fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8ac347e05b4462ab6b09944c744ff44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1f1bc767aae4a3d852d49b2b79da6b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(lightning_model, train_dataloaders=train_dataloader, val_dataloaders=valid_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471244fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
