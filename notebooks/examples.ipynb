{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b36126e-68e9-4714-9363-2427cc4b3099",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0339afcf-5a91-411c-8412-dfea5191b37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "import math\n",
    "from functools import partial\n",
    "from typing import Optional, Any, Dict, List\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "import datetime\n",
    "import json\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor, optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import v2\n",
    "from torchinfo import summary\n",
    "\n",
    "from PIL import Image\n",
    "import torchview\n",
    "\n",
    "import pynop\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "118aa519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 3, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.random.random((3, 5, 4))\n",
    "np.moveaxis(a,-1,0).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ce245e",
   "metadata": {},
   "source": [
    "# FNO model\n",
    "Here is an example of a model using FNO and U-FNO blocks as in [1] or [2].  \n",
    "In these works, the number of channels is quite small (36), as they do not use tucker factorization. Likewise, the number of fourier modes is only 10.  \n",
    "Therefore, this model is squite small, as it has only 1,175,241 parameters, thanks to the tucker factorization\n",
    "\n",
    "These values could be increased for example to 64 or 128 channels and 16 or even 32 fourier modes. Specifying a spectral compression ratio of 2 can also reduce drastically the number of parameters, but the compression effect must be tested.\n",
    "\n",
    "It is possible to add trainable positional encodings to the input data (set positional_encoding=True in the FNO class). You have to define the number of channels of this embedding (trainable_pos_encoding_dims) and its spectral representation (trainable_pos_encoding_modes).  \n",
    "Constant positional encodings are also possible (fixed_positional_encoding=True). It adds the normalized x and y coordinates to the input (+ 2 channels).\n",
    "\n",
    "[1] G. Wen, Z. Li, K. Azizzadenesheli, A. Anandkumar, and S. M. Benson. U-FNOâ€”an enhanced\n",
    "fourier neural operator-based deep-learning model for multiphase flow. Advances in Water\n",
    "Resources, 163:104180, 2022  \n",
    "[2] https://doi.org/10.1016/j.ress.2024.110392"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4582ea60",
   "metadata": {},
   "outputs": [],
   "source": [
    "FNOmodel = pynop.FNO(\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    modes=(10, 10),\n",
    "    hidden_channels=(36, 36, 36, 36, 36, 36),\n",
    "    blocks=[\"FNO\",\"FNO\",\"FNO\",\"UFNO\",\"UFNO\",\"UFNO\"],\n",
    "    spectral_compression_factor=(1, 1, 1),\n",
    "    trainable_pos_encoding=True,\n",
    "    fixed_pos_encoding=True,\n",
    "    trainable_pos_encoding_modes=(16, 16),  # Only useful if pos_encoding == 'trainable'\n",
    "    trainable_pos_encoding_dims=8,  # Only useful if pos_encoding == 'trainable' dimension of the embedding\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "298e15b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to run torchinfo. See above stack traces for more details. Executed layers up to: []",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.12/site-packages/torchinfo/torchinfo.py:295\u001b[0m, in \u001b[0;36mforward_pass\u001b[0;34m(model, x, batch_dim, cache_forward_pass, device, mode, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m--> 295\u001b[0m     _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.12/site-packages/torch/nn/modules/module.py:1845\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1844\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1845\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1847\u001b[0m     \u001b[38;5;66;03m# run always called hooks if they have not already been run\u001b[39;00m\n\u001b[1;32m   1848\u001b[0m     \u001b[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001b[39;00m\n\u001b[1;32m   1849\u001b[0m     \u001b[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.12/site-packages/torch/nn/modules/module.py:1793\u001b[0m, in \u001b[0;36mModule._call_impl.<locals>.inner\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1791\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1793\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.12/site-packages/pynop/models/FNO.py:86\u001b[0m, in \u001b[0;36mFNO.forward\u001b[0;34m(self, x, return_coords)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, return_coords\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m---> 86\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_coords\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfixed_pos_encoding:\n\u001b[1;32m     87\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     88\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn_coords is only available when fixed_pos_encoding or trainable_pos_encoding is True\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     89\u001b[0m         )\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.12/site-packages/torch/nn/modules/module.py:1928\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1927\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1928\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1929\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1930\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'FNO' object has no attribute 'return_coords'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mFNOmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_size\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_size\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_params\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkernel_size\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.12/site-packages/torchinfo/torchinfo.py:223\u001b[0m, in \u001b[0;36msummary\u001b[0;34m(model, input_size, input_data, batch_dim, cache_forward_pass, col_names, col_width, depth, device, dtypes, mode, row_settings, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    216\u001b[0m validate_user_params(\n\u001b[1;32m    217\u001b[0m     input_data, input_size, columns, col_width, device, dtypes, verbose\n\u001b[1;32m    218\u001b[0m )\n\u001b[1;32m    220\u001b[0m x, correct_input_size \u001b[38;5;241m=\u001b[39m process_input(\n\u001b[1;32m    221\u001b[0m     input_data, input_size, batch_dim, device, dtypes\n\u001b[1;32m    222\u001b[0m )\n\u001b[0;32m--> 223\u001b[0m summary_list \u001b[38;5;241m=\u001b[39m \u001b[43mforward_pass\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_forward_pass\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m formatting \u001b[38;5;241m=\u001b[39m FormattingOptions(depth, verbose, columns, col_width, rows)\n\u001b[1;32m    227\u001b[0m results \u001b[38;5;241m=\u001b[39m ModelStatistics(\n\u001b[1;32m    228\u001b[0m     summary_list, correct_input_size, get_total_memory_used(x), formatting\n\u001b[1;32m    229\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.12/site-packages/torchinfo/torchinfo.py:304\u001b[0m, in \u001b[0;36mforward_pass\u001b[0;34m(model, x, batch_dim, cache_forward_pass, device, mode, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    303\u001b[0m     executed_layers \u001b[38;5;241m=\u001b[39m [layer \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m summary_list \u001b[38;5;28;01mif\u001b[39;00m layer\u001b[38;5;241m.\u001b[39mexecuted]\n\u001b[0;32m--> 304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to run torchinfo. See above stack traces for more details. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecuted layers up to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexecuted_layers\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hooks:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to run torchinfo. See above stack traces for more details. Executed layers up to: []"
     ]
    }
   ],
   "source": [
    "summary(\n",
    "    FNOmodel, input_size=(2, 1, 128, 128), depth=10, col_names=[\"input_size\", \"output_size\", \"num_params\", \"kernel_size\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc957d6",
   "metadata": {},
   "source": [
    "# CoDANO\n",
    "This is a CoDANO model [3] using using FNO blocks to project the input variables to a latent space to be processed as tokens by a multi-head attention module.\n",
    "In this implementation, each variable is represneted by a channel in the input tensor (e.g. the velocity field has 2 channels, the pressure field has 1 channel, etc.).\n",
    "After adding an optional static field and the positional embeddings, the input tensor is lifted to a higher dimensal space using a linear layer (to hidden_variable_codimension channels).\n",
    "In eahc CoDANO layer, the input tensor is projected to K, V, Q matrix using FNO blocks. Each variable is processed by the same FNO block (shared block) to obtain the corresponding token.\n",
    "The Q, V, K tokens are then processed by a multi-head attention module, and the output is projected back to the original input space using a linear layer.\n",
    "\n",
    "Note that if a static field is defined in the class initiation, it must be provided when calling the model. You have to add this in the train loop!  \n",
    "\n",
    "This architecture can rapidly lead to very large models when the number of heads is increasing, even using a small latent dimension. \n",
    "\n",
    "[3] https://papers.nips.cc/paper_files/paper/2024/file/bc75fa9843a7905bbed9d83895a88f7f-Paper-Conference.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c067a95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CoDANO_model = pynop.CoDANO(\n",
    "    [\"ux\", \"uy\"],\n",
    "    n_heads=2,  # number of attention heads in each layer\n",
    "    n_layers=4, # number of CoDANO Layers (multihead attention + projection)\n",
    "    modes=(24, 24), # the number of modes in the FNO layers\n",
    "    static_channel_dim=1, # the number of static channels (e.g. the diffusivity field)\n",
    "    hidden_lifting_channels=64, # number of channels in the intermediate layer sof the lifting module (a series of 1x1 conv)\n",
    "    hidden_variable_codimension=32, # the latent dimension of each variable (after lifting)\n",
    "    positional_encoding_dim=8,  # the dimension of the positional encoding (before lifting)\n",
    "    positional_encoding_modes = (16, 16), # the number of modes in the positional encoding\n",
    "    per_channel_attention=False,    # if True, the attention is computed per channel (it decrease the number of parameters)\n",
    "    spectral_compression_factor=(2, 2, 2), # the compression factor for the spectral compression (in the FNO layers).\n",
    "    activation=partial(nn.GELU, approximate=\"tanh\"), # the activation function (must be class)\n",
    "    norm=partial(nn.InstanceNorm2d, affine=True), # the normalization layer (must be class)\n",
    "    ndim=2, # the number of dimensions (only 2D)\n",
    ")\n",
    "# model(torch.rand((2, 2, 128, 128))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91ca51ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to run torchinfo. See above stack traces for more details. Executed layers up to: []",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.12/site-packages/torchinfo/torchinfo.py:295\u001b[0m, in \u001b[0;36mforward_pass\u001b[0;34m(model, x, batch_dim, cache_forward_pass, device, mode, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m--> 295\u001b[0m     _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.12/site-packages/torch/nn/modules/module.py:1845\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1844\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1845\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1847\u001b[0m     \u001b[38;5;66;03m# run always called hooks if they have not already been run\u001b[39;00m\n\u001b[1;32m   1848\u001b[0m     \u001b[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001b[39;00m\n\u001b[1;32m   1849\u001b[0m     \u001b[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.12/site-packages/torch/nn/modules/module.py:1793\u001b[0m, in \u001b[0;36mModule._call_impl.<locals>.inner\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1791\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1793\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.12/site-packages/pynop/models/CoDANO.py:240\u001b[0m, in \u001b[0;36mCoDANO.forward\u001b[0;34m(self, x, static_channel, return_coords)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;66;03m# concatenate  positional encodings and static fields for each variables\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;66;03m# (batch_size, num_inp_var, extended_variable_codimemsion, H, W)\u001b[39;00m\n\u001b[0;32m--> 240\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extend_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatic_channel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_coords \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfixed_pos_encoding:\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.12/site-packages/pynop/models/CoDANO.py:191\u001b[0m, in \u001b[0;36mCoDANO._extend_variables\u001b[0;34m(self, x, static_channel)\u001b[0m\n\u001b[1;32m    190\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# (batch_size, num_inp_var, 1, H, W)\u001b[39;00m\n\u001b[0;32m--> 191\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid_encoding\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (batch_size, num_inp_var, 1 + 2, H, W)\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Tensors must have same number of dimensions: got 5 and 4",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mCoDANO_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Here we must pass the static field as an input to the model forward method -> [input_tensor, static field]\u001b[39;49;00m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcol_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_size\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_size\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_params\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkernel_size\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.12/site-packages/torchinfo/torchinfo.py:223\u001b[0m, in \u001b[0;36msummary\u001b[0;34m(model, input_size, input_data, batch_dim, cache_forward_pass, col_names, col_width, depth, device, dtypes, mode, row_settings, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    216\u001b[0m validate_user_params(\n\u001b[1;32m    217\u001b[0m     input_data, input_size, columns, col_width, device, dtypes, verbose\n\u001b[1;32m    218\u001b[0m )\n\u001b[1;32m    220\u001b[0m x, correct_input_size \u001b[38;5;241m=\u001b[39m process_input(\n\u001b[1;32m    221\u001b[0m     input_data, input_size, batch_dim, device, dtypes\n\u001b[1;32m    222\u001b[0m )\n\u001b[0;32m--> 223\u001b[0m summary_list \u001b[38;5;241m=\u001b[39m \u001b[43mforward_pass\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_forward_pass\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m formatting \u001b[38;5;241m=\u001b[39m FormattingOptions(depth, verbose, columns, col_width, rows)\n\u001b[1;32m    227\u001b[0m results \u001b[38;5;241m=\u001b[39m ModelStatistics(\n\u001b[1;32m    228\u001b[0m     summary_list, correct_input_size, get_total_memory_used(x), formatting\n\u001b[1;32m    229\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.12/site-packages/torchinfo/torchinfo.py:304\u001b[0m, in \u001b[0;36mforward_pass\u001b[0;34m(model, x, batch_dim, cache_forward_pass, device, mode, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    303\u001b[0m     executed_layers \u001b[38;5;241m=\u001b[39m [layer \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m summary_list \u001b[38;5;28;01mif\u001b[39;00m layer\u001b[38;5;241m.\u001b[39mexecuted]\n\u001b[0;32m--> 304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to run torchinfo. See above stack traces for more details. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecuted layers up to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexecuted_layers\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hooks:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to run torchinfo. See above stack traces for more details. Executed layers up to: []"
     ]
    }
   ],
   "source": [
    "summary(\n",
    "    CoDANO_model,\n",
    "    input_size=[(2, 2, 128, 128), (2, 1, 128, 128)], # Here we must pass the static field as an input to the model forward method -> [input_tensor, static field]\n",
    "    depth=10,\n",
    "    col_names=[\"input_size\", \"output_size\", \"num_params\", \"kernel_size\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84f5698-c035-4bdf-a856-47d57de1ed33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize config dict\n",
    "def serialize(dictionnary):\n",
    "    serialized = {}\n",
    "    for k, v in dictionnary.items():\n",
    "        try:\n",
    "            serialized[k] = v.__name__\n",
    "        except AttributeError:\n",
    "            serialized[k] = v\n",
    "    return serialized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7dd543a",
   "metadata": {},
   "source": [
    "# Encoder-decoder\n",
    "An exampler of the building of an encoder-decoder model using residual blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acacae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_block = partial(pynop.core.ResBlock, norm=[None, pynop.LayerNorm2d], activation=[nn.SiLU, None], use_bias=[True, False])\n",
    "upblock = partial(pynop.InterpolateConvUpSampleLayer, kernel_size=1, factor=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc7d2c9-d241-43de-8807-69ede93fa52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_config = {\n",
    "    \"in_channels\": 3,\n",
    "    \"latent_dim\": 32,\n",
    "    \"block\": base_block,\n",
    "    \"downblock\": None,  # if downblock is None, the downsampling is done in the first block of each stage using a stride 2\n",
    "    \"depths\": [2, 2, 2],\n",
    "    \"dims\": [64, 64, 64],\n",
    "    \"stem_kernel_size\": 3,\n",
    "    \"stem_norm\": pynop.RMSNorm2d,\n",
    "    \"stem_activation\": nn.SiLU,\n",
    "}\n",
    "\n",
    "\n",
    "dec_config = {\n",
    "    \"out_channels\": 3,\n",
    "    \"latent_dim\": 32,\n",
    "    \"block\": base_block,\n",
    "    \"upblock\": upblock,\n",
    "    \"depths\": [2, 2, 2],\n",
    "    \"dims\": [64, 64, 64],\n",
    "}\n",
    "\n",
    "\n",
    "encoder = pynop.models.Encoder(**enc_config)\n",
    "\n",
    "decoder = pynop.models.Decoder(**dec_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b413bf9d-750d-4157-8e4d-335680c1de36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg = dc_ae_f32c32(name=\"dc-ae-f32c32-in-1.0\", pretrained_path=None)\n",
    "generator = pynop.models.AutoEncoder(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9e9d78a4-7ec4-4a03-aa10-afb6e7bb572d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===========================================================================================================================================================\n",
       "Layer (type:depth-idx)                                  Input Shape               Output Shape              Param #                   Kernel Shape\n",
       "===========================================================================================================================================================\n",
       "AutoEncoder                                             [2, 3, 96, 96]            [2, 3, 96, 96]            --                        --\n",
       "â”œâ”€Encoder: 1-1                                          [2, 3, 96, 96]            [2, 32, 12, 12]           --                        --\n",
       "â”‚    â””â”€ConvLayer: 2-1                                   [2, 3, 96, 96]            [2, 64, 96, 96]           --                        --\n",
       "â”‚    â”‚    â””â”€ModuleList: 3-1                             --                        --                        64                        --\n",
       "â”‚    â”‚    â”‚    â””â”€ZeroPad2d: 4-1                         [2, 3, 96, 96]            [2, 3, 98, 98]            --                        --\n",
       "â”‚    â”‚    â”‚    â””â”€Conv2d: 4-2                            [2, 3, 98, 98]            [2, 64, 96, 96]           1,728                     [3, 3]\n",
       "â”‚    â”‚    â””â”€RMSNorm2d: 3-2                              [2, 64, 96, 96]           [2, 64, 96, 96]           64                        --\n",
       "â”‚    â”‚    â””â”€SiLU: 3-3                                   [2, 64, 96, 96]           [2, 64, 96, 96]           --                        --\n",
       "â”‚    â””â”€ModuleList: 2-2                                  --                        --                        --                        --\n",
       "â”‚    â”‚    â””â”€ResBlock: 3-4                               [2, 64, 96, 96]           [2, 64, 48, 48]           --                        --\n",
       "â”‚    â”‚    â”‚    â””â”€ModuleList: 4-3                        --                        --                        --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â””â”€ConvLayer: 5-1                    [2, 64, 96, 96]           [2, 64, 48, 48]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€ModuleList: 6-1              --                        --                        --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€ZeroPad2d: 7-1          [2, 64, 96, 96]           [2, 64, 98, 98]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€Conv2d: 7-2             [2, 64, 98, 98]           [2, 64, 48, 48]           36,928                    [3, 3]\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€SiLU: 6-2                    [2, 64, 48, 48]           [2, 64, 48, 48]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â””â”€ConvLayer: 5-2                    [2, 64, 48, 48]           [2, 64, 48, 48]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€ModuleList: 6-3              --                        --                        128                       --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€ZeroPad2d: 7-3          [2, 64, 48, 48]           [2, 64, 50, 50]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€Conv2d: 7-4             [2, 64, 50, 50]           [2, 64, 48, 48]           36,864                    [3, 3]\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€LayerNorm2d: 6-4             [2, 64, 48, 48]           [2, 64, 48, 48]           128                       --\n",
       "â”‚    â”‚    â”‚    â””â”€MaxPoolConv: 4-4                       [2, 64, 96, 96]           [2, 64, 48, 48]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â””â”€MaxPool2d: 5-3                    [2, 64, 96, 96]           [2, 64, 48, 48]           --                        1\n",
       "â”‚    â”‚    â”‚    â”‚    â””â”€ConvLayer: 5-4                    [2, 64, 48, 48]           [2, 64, 48, 48]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€ModuleList: 6-5              --                        --                        --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€ZeroPad2d: 7-5          [2, 64, 48, 48]           [2, 64, 48, 48]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€Conv2d: 7-6             [2, 64, 48, 48]           [2, 64, 48, 48]           4,160                     [1, 1]\n",
       "â”‚    â”‚    â””â”€ResBlock: 3-5                               [2, 64, 48, 48]           [2, 64, 48, 48]           --                        --\n",
       "â”‚    â”‚    â”‚    â””â”€ModuleList: 4-5                        --                        --                        --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â””â”€ConvLayer: 5-5                    [2, 64, 48, 48]           [2, 64, 48, 48]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€ModuleList: 6-6              --                        --                        --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€ZeroPad2d: 7-7          [2, 64, 48, 48]           [2, 64, 50, 50]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€Conv2d: 7-8             [2, 64, 50, 50]           [2, 64, 48, 48]           36,928                    [3, 3]\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€SiLU: 6-7                    [2, 64, 48, 48]           [2, 64, 48, 48]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â””â”€ConvLayer: 5-6                    [2, 64, 48, 48]           [2, 64, 48, 48]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€ModuleList: 6-8              --                        --                        128                       --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€ZeroPad2d: 7-9          [2, 64, 48, 48]           [2, 64, 50, 50]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€Conv2d: 7-10            [2, 64, 50, 50]           [2, 64, 48, 48]           36,864                    [3, 3]\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€LayerNorm2d: 6-9             [2, 64, 48, 48]           [2, 64, 48, 48]           128                       --\n",
       "â”‚    â”‚    â””â”€ResBlock: 3-6                               [2, 64, 48, 48]           [2, 64, 24, 24]           --                        --\n",
       "â”‚    â”‚    â”‚    â””â”€ModuleList: 4-6                        --                        --                        --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â””â”€ConvLayer: 5-7                    [2, 64, 48, 48]           [2, 64, 24, 24]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€ModuleList: 6-10             --                        --                        --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€ZeroPad2d: 7-11         [2, 64, 48, 48]           [2, 64, 50, 50]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€Conv2d: 7-12            [2, 64, 50, 50]           [2, 64, 24, 24]           36,928                    [3, 3]\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€SiLU: 6-11                   [2, 64, 24, 24]           [2, 64, 24, 24]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â””â”€ConvLayer: 5-8                    [2, 64, 24, 24]           [2, 64, 24, 24]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€ModuleList: 6-12             --                        --                        128                       --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€ZeroPad2d: 7-13         [2, 64, 24, 24]           [2, 64, 26, 26]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€Conv2d: 7-14            [2, 64, 26, 26]           [2, 64, 24, 24]           36,864                    [3, 3]\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€LayerNorm2d: 6-13            [2, 64, 24, 24]           [2, 64, 24, 24]           128                       --\n",
       "â”‚    â”‚    â”‚    â””â”€MaxPoolConv: 4-7                       [2, 64, 48, 48]           [2, 64, 24, 24]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â””â”€MaxPool2d: 5-9                    [2, 64, 48, 48]           [2, 64, 24, 24]           --                        1\n",
       "â”‚    â”‚    â”‚    â”‚    â””â”€ConvLayer: 5-10                   [2, 64, 24, 24]           [2, 64, 24, 24]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€ModuleList: 6-14             --                        --                        --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€ZeroPad2d: 7-15         [2, 64, 24, 24]           [2, 64, 24, 24]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€Conv2d: 7-16            [2, 64, 24, 24]           [2, 64, 24, 24]           4,160                     [1, 1]\n",
       "â”‚    â”‚    â””â”€ResBlock: 3-7                               [2, 64, 24, 24]           [2, 64, 24, 24]           --                        --\n",
       "â”‚    â”‚    â”‚    â””â”€ModuleList: 4-8                        --                        --                        --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â””â”€ConvLayer: 5-11                   [2, 64, 24, 24]           [2, 64, 24, 24]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€ModuleList: 6-15             --                        --                        --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€ZeroPad2d: 7-17         [2, 64, 24, 24]           [2, 64, 26, 26]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€Conv2d: 7-18            [2, 64, 26, 26]           [2, 64, 24, 24]           36,928                    [3, 3]\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€SiLU: 6-16                   [2, 64, 24, 24]           [2, 64, 24, 24]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â””â”€ConvLayer: 5-12                   [2, 64, 24, 24]           [2, 64, 24, 24]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€ModuleList: 6-17             --                        --                        128                       --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€ZeroPad2d: 7-19         [2, 64, 24, 24]           [2, 64, 26, 26]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€Conv2d: 7-20            [2, 64, 26, 26]           [2, 64, 24, 24]           36,864                    [3, 3]\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€LayerNorm2d: 6-18            [2, 64, 24, 24]           [2, 64, 24, 24]           128                       --\n",
       "â”‚    â”‚    â””â”€ResBlock: 3-8                               [2, 64, 24, 24]           [2, 64, 12, 12]           --                        --\n",
       "â”‚    â”‚    â”‚    â””â”€ModuleList: 4-9                        --                        --                        --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â””â”€ConvLayer: 5-13                   [2, 64, 24, 24]           [2, 64, 12, 12]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€ModuleList: 6-19             --                        --                        --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€ZeroPad2d: 7-21         [2, 64, 24, 24]           [2, 64, 26, 26]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€Conv2d: 7-22            [2, 64, 26, 26]           [2, 64, 12, 12]           36,928                    [3, 3]\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€SiLU: 6-20                   [2, 64, 12, 12]           [2, 64, 12, 12]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â””â”€ConvLayer: 5-14                   [2, 64, 12, 12]           [2, 64, 12, 12]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€ModuleList: 6-21             --                        --                        128                       --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€ZeroPad2d: 7-23         [2, 64, 12, 12]           [2, 64, 14, 14]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€Conv2d: 7-24            [2, 64, 14, 14]           [2, 64, 12, 12]           36,864                    [3, 3]\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€LayerNorm2d: 6-22            [2, 64, 12, 12]           [2, 64, 12, 12]           128                       --\n",
       "â”‚    â”‚    â”‚    â””â”€MaxPoolConv: 4-10                      [2, 64, 24, 24]           [2, 64, 12, 12]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â””â”€MaxPool2d: 5-15                   [2, 64, 24, 24]           [2, 64, 12, 12]           --                        1\n",
       "â”‚    â”‚    â”‚    â”‚    â””â”€ConvLayer: 5-16                   [2, 64, 12, 12]           [2, 64, 12, 12]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€ModuleList: 6-23             --                        --                        --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€ZeroPad2d: 7-25         [2, 64, 12, 12]           [2, 64, 12, 12]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€Conv2d: 7-26            [2, 64, 12, 12]           [2, 64, 12, 12]           4,160                     [1, 1]\n",
       "â”‚    â”‚    â””â”€ResBlock: 3-9                               [2, 64, 12, 12]           [2, 64, 12, 12]           --                        --\n",
       "â”‚    â”‚    â”‚    â””â”€ModuleList: 4-11                       --                        --                        --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â””â”€ConvLayer: 5-17                   [2, 64, 12, 12]           [2, 64, 12, 12]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€ModuleList: 6-24             --                        --                        --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€ZeroPad2d: 7-27         [2, 64, 12, 12]           [2, 64, 14, 14]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€Conv2d: 7-28            [2, 64, 14, 14]           [2, 64, 12, 12]           36,928                    [3, 3]\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€SiLU: 6-25                   [2, 64, 12, 12]           [2, 64, 12, 12]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â””â”€ConvLayer: 5-18                   [2, 64, 12, 12]           [2, 64, 12, 12]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€ModuleList: 6-26             --                        --                        128                       --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€ZeroPad2d: 7-29         [2, 64, 12, 12]           [2, 64, 14, 14]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€Conv2d: 7-30            [2, 64, 14, 14]           [2, 64, 12, 12]           36,864                    [3, 3]\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€LayerNorm2d: 6-27            [2, 64, 12, 12]           [2, 64, 12, 12]           128                       --\n",
       "â”‚    â””â”€Conv2d: 2-3                                      [2, 64, 12, 12]           [2, 32, 12, 12]           2,080                     [1, 1]\n",
       "â”œâ”€Decoder: 1-2                                          [2, 32, 12, 12]           [2, 3, 96, 96]            --                        --\n",
       "â”‚    â””â”€ModuleList: 2-4                                  --                        --                        --                        --\n",
       "â”‚    â”‚    â””â”€InterpolateConvUpSampleLayer: 3-10          [2, 32, 12, 12]           [2, 64, 24, 24]           --                        --\n",
       "â”‚    â”‚    â”‚    â””â”€ConvLayer: 4-12                        [2, 32, 24, 24]           [2, 64, 24, 24]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â””â”€ModuleList: 5-19                  --                        --                        --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€ZeroPad2d: 6-28              [2, 32, 24, 24]           [2, 32, 24, 24]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€Conv2d: 6-29                 [2, 32, 24, 24]           [2, 64, 24, 24]           2,112                     [1, 1]\n",
       "â”‚    â”‚    â””â”€ResBlock: 3-11                              [2, 64, 24, 24]           [2, 64, 24, 24]           --                        --\n",
       "â”‚    â”‚    â”‚    â””â”€ModuleList: 4-13                       --                        --                        --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â””â”€ConvLayer: 5-20                   [2, 64, 24, 24]           [2, 64, 24, 24]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€ModuleList: 6-30             --                        --                        --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€ZeroPad2d: 7-31         [2, 64, 24, 24]           [2, 64, 26, 26]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€Conv2d: 7-32            [2, 64, 26, 26]           [2, 64, 24, 24]           36,928                    [3, 3]\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€SiLU: 6-31                   [2, 64, 24, 24]           [2, 64, 24, 24]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â””â”€ConvLayer: 5-21                   [2, 64, 24, 24]           [2, 64, 24, 24]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€ModuleList: 6-32             --                        --                        128                       --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€ZeroPad2d: 7-33         [2, 64, 24, 24]           [2, 64, 26, 26]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€Conv2d: 7-34            [2, 64, 26, 26]           [2, 64, 24, 24]           36,864                    [3, 3]\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€LayerNorm2d: 6-33            [2, 64, 24, 24]           [2, 64, 24, 24]           128                       --\n",
       "â”‚    â”‚    â””â”€ResBlock: 3-12                              [2, 64, 24, 24]           [2, 64, 24, 24]           --                        --\n",
       "â”‚    â”‚    â”‚    â””â”€ModuleList: 4-14                       --                        --                        --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â””â”€ConvLayer: 5-22                   [2, 64, 24, 24]           [2, 64, 24, 24]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€ModuleList: 6-34             --                        --                        --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€ZeroPad2d: 7-35         [2, 64, 24, 24]           [2, 64, 26, 26]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€Conv2d: 7-36            [2, 64, 26, 26]           [2, 64, 24, 24]           36,928                    [3, 3]\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€SiLU: 6-35                   [2, 64, 24, 24]           [2, 64, 24, 24]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â””â”€ConvLayer: 5-23                   [2, 64, 24, 24]           [2, 64, 24, 24]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€ModuleList: 6-36             --                        --                        128                       --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€ZeroPad2d: 7-37         [2, 64, 24, 24]           [2, 64, 26, 26]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€Conv2d: 7-38            [2, 64, 26, 26]           [2, 64, 24, 24]           36,864                    [3, 3]\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€LayerNorm2d: 6-37            [2, 64, 24, 24]           [2, 64, 24, 24]           128                       --\n",
       "â”‚    â”‚    â””â”€InterpolateConvUpSampleLayer: 3-13          [2, 64, 24, 24]           [2, 64, 48, 48]           --                        --\n",
       "â”‚    â”‚    â”‚    â””â”€ConvLayer: 4-15                        [2, 64, 48, 48]           [2, 64, 48, 48]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â””â”€ModuleList: 5-24                  --                        --                        --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€ZeroPad2d: 6-38              [2, 64, 48, 48]           [2, 64, 48, 48]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€Conv2d: 6-39                 [2, 64, 48, 48]           [2, 64, 48, 48]           4,160                     [1, 1]\n",
       "â”‚    â”‚    â””â”€ResBlock: 3-14                              [2, 64, 48, 48]           [2, 64, 48, 48]           --                        --\n",
       "â”‚    â”‚    â”‚    â””â”€ModuleList: 4-16                       --                        --                        --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â””â”€ConvLayer: 5-25                   [2, 64, 48, 48]           [2, 64, 48, 48]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€ModuleList: 6-40             --                        --                        --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€ZeroPad2d: 7-39         [2, 64, 48, 48]           [2, 64, 50, 50]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€Conv2d: 7-40            [2, 64, 50, 50]           [2, 64, 48, 48]           36,928                    [3, 3]\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€SiLU: 6-41                   [2, 64, 48, 48]           [2, 64, 48, 48]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â””â”€ConvLayer: 5-26                   [2, 64, 48, 48]           [2, 64, 48, 48]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€ModuleList: 6-42             --                        --                        128                       --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€ZeroPad2d: 7-41         [2, 64, 48, 48]           [2, 64, 50, 50]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€Conv2d: 7-42            [2, 64, 50, 50]           [2, 64, 48, 48]           36,864                    [3, 3]\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€LayerNorm2d: 6-43            [2, 64, 48, 48]           [2, 64, 48, 48]           128                       --\n",
       "â”‚    â”‚    â””â”€ResBlock: 3-15                              [2, 64, 48, 48]           [2, 64, 48, 48]           --                        --\n",
       "â”‚    â”‚    â”‚    â””â”€ModuleList: 4-17                       --                        --                        --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â””â”€ConvLayer: 5-27                   [2, 64, 48, 48]           [2, 64, 48, 48]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€ModuleList: 6-44             --                        --                        --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€ZeroPad2d: 7-43         [2, 64, 48, 48]           [2, 64, 50, 50]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€Conv2d: 7-44            [2, 64, 50, 50]           [2, 64, 48, 48]           36,928                    [3, 3]\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€SiLU: 6-45                   [2, 64, 48, 48]           [2, 64, 48, 48]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â””â”€ConvLayer: 5-28                   [2, 64, 48, 48]           [2, 64, 48, 48]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€ModuleList: 6-46             --                        --                        128                       --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€ZeroPad2d: 7-45         [2, 64, 48, 48]           [2, 64, 50, 50]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€Conv2d: 7-46            [2, 64, 50, 50]           [2, 64, 48, 48]           36,864                    [3, 3]\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€LayerNorm2d: 6-47            [2, 64, 48, 48]           [2, 64, 48, 48]           128                       --\n",
       "â”‚    â”‚    â””â”€InterpolateConvUpSampleLayer: 3-16          [2, 64, 48, 48]           [2, 64, 96, 96]           --                        --\n",
       "â”‚    â”‚    â”‚    â””â”€ConvLayer: 4-18                        [2, 64, 96, 96]           [2, 64, 96, 96]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â””â”€ModuleList: 5-29                  --                        --                        --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€ZeroPad2d: 6-48              [2, 64, 96, 96]           [2, 64, 96, 96]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€Conv2d: 6-49                 [2, 64, 96, 96]           [2, 64, 96, 96]           4,160                     [1, 1]\n",
       "â”‚    â”‚    â””â”€ResBlock: 3-17                              [2, 64, 96, 96]           [2, 64, 96, 96]           --                        --\n",
       "â”‚    â”‚    â”‚    â””â”€ModuleList: 4-19                       --                        --                        --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â””â”€ConvLayer: 5-30                   [2, 64, 96, 96]           [2, 64, 96, 96]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€ModuleList: 6-50             --                        --                        --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€ZeroPad2d: 7-47         [2, 64, 96, 96]           [2, 64, 98, 98]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€Conv2d: 7-48            [2, 64, 98, 98]           [2, 64, 96, 96]           36,928                    [3, 3]\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€SiLU: 6-51                   [2, 64, 96, 96]           [2, 64, 96, 96]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â””â”€ConvLayer: 5-31                   [2, 64, 96, 96]           [2, 64, 96, 96]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€ModuleList: 6-52             --                        --                        128                       --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€ZeroPad2d: 7-49         [2, 64, 96, 96]           [2, 64, 98, 98]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€Conv2d: 7-50            [2, 64, 98, 98]           [2, 64, 96, 96]           36,864                    [3, 3]\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€LayerNorm2d: 6-53            [2, 64, 96, 96]           [2, 64, 96, 96]           128                       --\n",
       "â”‚    â”‚    â””â”€ResBlock: 3-18                              [2, 64, 96, 96]           [2, 64, 96, 96]           --                        --\n",
       "â”‚    â”‚    â”‚    â””â”€ModuleList: 4-20                       --                        --                        --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â””â”€ConvLayer: 5-32                   [2, 64, 96, 96]           [2, 64, 96, 96]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€ModuleList: 6-54             --                        --                        --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€ZeroPad2d: 7-51         [2, 64, 96, 96]           [2, 64, 98, 98]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€Conv2d: 7-52            [2, 64, 98, 98]           [2, 64, 96, 96]           36,928                    [3, 3]\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€SiLU: 6-55                   [2, 64, 96, 96]           [2, 64, 96, 96]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â””â”€ConvLayer: 5-33                   [2, 64, 96, 96]           [2, 64, 96, 96]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€ModuleList: 6-56             --                        --                        128                       --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€ZeroPad2d: 7-53         [2, 64, 96, 96]           [2, 64, 98, 98]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€Conv2d: 7-54            [2, 64, 98, 98]           [2, 64, 96, 96]           36,864                    [3, 3]\n",
       "â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€LayerNorm2d: 6-57            [2, 64, 96, 96]           [2, 64, 96, 96]           128                       --\n",
       "â”‚    â””â”€ConvLayer: 2-5                                   [2, 64, 96, 96]           [2, 3, 96, 96]            --                        --\n",
       "â”‚    â”‚    â””â”€ModuleList: 3-19                            --                        --                        --                        --\n",
       "â”‚    â”‚    â”‚    â””â”€ZeroPad2d: 4-21                        [2, 64, 96, 96]           [2, 64, 96, 96]           --                        --\n",
       "â”‚    â”‚    â”‚    â””â”€Conv2d: 4-22                           [2, 64, 96, 96]           [2, 3, 96, 96]            195                       [1, 1]\n",
       "===========================================================================================================================================================\n",
       "Total params: 915,619\n",
       "Trainable params: 915,619\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 4.62\n",
       "===========================================================================================================================================================\n",
       "Input size (MB): 0.22\n",
       "Forward/backward pass size (MB): 127.77\n",
       "Params size (MB): 3.66\n",
       "Estimated Total Size (MB): 131.65\n",
       "==========================================================================================================================================================="
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(\n",
    "    generator, input_size=(2, 3, 96, 96), depth=8, col_names=[\"input_size\", \"output_size\", \"num_params\", \"kernel_size\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ed1b3b",
   "metadata": {},
   "source": [
    "# UNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58b727dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynop.core.norm import LayerNorm2d\n",
    "from pynop.models import unet\n",
    "\n",
    "block = partial(pynop.core.ResBlock, norm=[None, pynop.LayerNorm2d], activation=[nn.GELU, None], use_bias=[True, False])\n",
    "block = partial(pynop.ops.ConvLayer,norm=LayerNorm2d, activation=nn.GELU, stride=1)\n",
    "\n",
    "unetmodel = unet(\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    block=block,\n",
    "    filters=(32, 64, 128, 256),\n",
    "    repeats=(2, 2, 2, 2),\n",
    "    stem_stride=2,\n",
    "    stem_kernel_size=3,\n",
    "    stem_norm=pynop.LayerNorm2d,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac81fe0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlux/miniforge3/envs/AI/lib/python3.12/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "=================================================================================================================================================\n",
       "Layer (type:depth-idx)                        Input Shape               Output Shape              Param #                   Kernel Shape\n",
       "=================================================================================================================================================\n",
       "unet                                          [2, 1, 128, 128]          [2, 1, 128, 128]          --                        --\n",
       "â”œâ”€ConvLayer: 1-1                              [2, 1, 128, 128]          [2, 32, 64, 64]           --                        --\n",
       "â”‚    â””â”€ModuleList: 2-1                        --                        --                        64                        --\n",
       "â”‚    â”‚    â””â”€ZeroPad2d: 3-1                    [2, 1, 128, 128]          [2, 1, 130, 130]          --                        --\n",
       "â”‚    â”‚    â””â”€Conv2d: 3-2                       [2, 1, 130, 130]          [2, 32, 64, 64]           288                       [3, 3]\n",
       "â”‚    â””â”€LayerNorm2d: 2-2                       [2, 32, 64, 64]           [2, 32, 64, 64]           64                        --\n",
       "â”‚    â””â”€GELU: 2-3                              [2, 32, 64, 64]           [2, 32, 64, 64]           --                        --\n",
       "â”œâ”€ModuleList: 1-8                             --                        --                        (recursive)               --\n",
       "â”‚    â””â”€ConvLayer: 2-4                         [2, 32, 64, 64]           [2, 32, 64, 64]           --                        --\n",
       "â”‚    â”‚    â””â”€ModuleList: 3-3                   --                        --                        64                        --\n",
       "â”‚    â”‚    â”‚    â””â”€ZeroPad2d: 4-1               [2, 32, 64, 64]           [2, 32, 66, 66]           --                        --\n",
       "â”‚    â”‚    â”‚    â””â”€Conv2d: 4-2                  [2, 32, 66, 66]           [2, 32, 64, 64]           9,216                     [3, 3]\n",
       "â”‚    â”‚    â””â”€LayerNorm2d: 3-4                  [2, 32, 64, 64]           [2, 32, 64, 64]           64                        --\n",
       "â”‚    â”‚    â””â”€GELU: 3-5                         [2, 32, 64, 64]           [2, 32, 64, 64]           --                        --\n",
       "â”‚    â””â”€ConvLayer: 2-5                         [2, 32, 64, 64]           [2, 32, 64, 64]           --                        --\n",
       "â”‚    â”‚    â””â”€ModuleList: 3-6                   --                        --                        64                        --\n",
       "â”‚    â”‚    â”‚    â””â”€ZeroPad2d: 4-3               [2, 32, 64, 64]           [2, 32, 66, 66]           --                        --\n",
       "â”‚    â”‚    â”‚    â””â”€Conv2d: 4-4                  [2, 32, 66, 66]           [2, 32, 64, 64]           9,216                     [3, 3]\n",
       "â”‚    â”‚    â””â”€LayerNorm2d: 3-7                  [2, 32, 64, 64]           [2, 32, 64, 64]           64                        --\n",
       "â”‚    â”‚    â””â”€GELU: 3-8                         [2, 32, 64, 64]           [2, 32, 64, 64]           --                        --\n",
       "â”œâ”€ModuleList: 1-7                             --                        --                        (recursive)               --\n",
       "â”‚    â””â”€MaxPoolConv: 2-6                       [2, 32, 64, 64]           [2, 32, 32, 32]           --                        --\n",
       "â”‚    â”‚    â””â”€MaxPool2d: 3-9                    [2, 32, 64, 64]           [2, 32, 32, 32]           --                        2\n",
       "â”‚    â”‚    â””â”€ConvLayer: 3-10                   [2, 32, 32, 32]           [2, 32, 32, 32]           --                        --\n",
       "â”‚    â”‚    â”‚    â””â”€ModuleList: 4-5              --                        --                        --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â””â”€ZeroPad2d: 5-1          [2, 32, 32, 32]           [2, 32, 32, 32]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â””â”€Conv2d: 5-2             [2, 32, 32, 32]           [2, 32, 32, 32]           1,056                     [1, 1]\n",
       "â”œâ”€ModuleList: 1-8                             --                        --                        (recursive)               --\n",
       "â”‚    â””â”€ConvLayer: 2-7                         [2, 32, 32, 32]           [2, 64, 32, 32]           --                        --\n",
       "â”‚    â”‚    â””â”€ModuleList: 3-11                  --                        --                        128                       --\n",
       "â”‚    â”‚    â”‚    â””â”€ZeroPad2d: 4-6               [2, 32, 32, 32]           [2, 32, 34, 34]           --                        --\n",
       "â”‚    â”‚    â”‚    â””â”€Conv2d: 4-7                  [2, 32, 34, 34]           [2, 64, 32, 32]           18,432                    [3, 3]\n",
       "â”‚    â”‚    â””â”€LayerNorm2d: 3-12                 [2, 64, 32, 32]           [2, 64, 32, 32]           128                       --\n",
       "â”‚    â”‚    â””â”€GELU: 3-13                        [2, 64, 32, 32]           [2, 64, 32, 32]           --                        --\n",
       "â”‚    â””â”€ConvLayer: 2-8                         [2, 64, 32, 32]           [2, 64, 32, 32]           --                        --\n",
       "â”‚    â”‚    â””â”€ModuleList: 3-14                  --                        --                        128                       --\n",
       "â”‚    â”‚    â”‚    â””â”€ZeroPad2d: 4-8               [2, 64, 32, 32]           [2, 64, 34, 34]           --                        --\n",
       "â”‚    â”‚    â”‚    â””â”€Conv2d: 4-9                  [2, 64, 34, 34]           [2, 64, 32, 32]           36,864                    [3, 3]\n",
       "â”‚    â”‚    â””â”€LayerNorm2d: 3-15                 [2, 64, 32, 32]           [2, 64, 32, 32]           128                       --\n",
       "â”‚    â”‚    â””â”€GELU: 3-16                        [2, 64, 32, 32]           [2, 64, 32, 32]           --                        --\n",
       "â”œâ”€ModuleList: 1-7                             --                        --                        (recursive)               --\n",
       "â”‚    â””â”€MaxPoolConv: 2-9                       [2, 64, 32, 32]           [2, 64, 16, 16]           --                        --\n",
       "â”‚    â”‚    â””â”€MaxPool2d: 3-17                   [2, 64, 32, 32]           [2, 64, 16, 16]           --                        2\n",
       "â”‚    â”‚    â””â”€ConvLayer: 3-18                   [2, 64, 16, 16]           [2, 64, 16, 16]           --                        --\n",
       "â”‚    â”‚    â”‚    â””â”€ModuleList: 4-10             --                        --                        --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â””â”€ZeroPad2d: 5-3          [2, 64, 16, 16]           [2, 64, 16, 16]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â””â”€Conv2d: 5-4             [2, 64, 16, 16]           [2, 64, 16, 16]           4,160                     [1, 1]\n",
       "â”œâ”€ModuleList: 1-8                             --                        --                        (recursive)               --\n",
       "â”‚    â””â”€ConvLayer: 2-10                        [2, 64, 16, 16]           [2, 128, 16, 16]          --                        --\n",
       "â”‚    â”‚    â””â”€ModuleList: 3-19                  --                        --                        256                       --\n",
       "â”‚    â”‚    â”‚    â””â”€ZeroPad2d: 4-11              [2, 64, 16, 16]           [2, 64, 18, 18]           --                        --\n",
       "â”‚    â”‚    â”‚    â””â”€Conv2d: 4-12                 [2, 64, 18, 18]           [2, 128, 16, 16]          73,728                    [3, 3]\n",
       "â”‚    â”‚    â””â”€LayerNorm2d: 3-20                 [2, 128, 16, 16]          [2, 128, 16, 16]          256                       --\n",
       "â”‚    â”‚    â””â”€GELU: 3-21                        [2, 128, 16, 16]          [2, 128, 16, 16]          --                        --\n",
       "â”‚    â””â”€ConvLayer: 2-11                        [2, 128, 16, 16]          [2, 128, 16, 16]          --                        --\n",
       "â”‚    â”‚    â””â”€ModuleList: 3-22                  --                        --                        256                       --\n",
       "â”‚    â”‚    â”‚    â””â”€ZeroPad2d: 4-13              [2, 128, 16, 16]          [2, 128, 18, 18]          --                        --\n",
       "â”‚    â”‚    â”‚    â””â”€Conv2d: 4-14                 [2, 128, 18, 18]          [2, 128, 16, 16]          147,456                   [3, 3]\n",
       "â”‚    â”‚    â””â”€LayerNorm2d: 3-23                 [2, 128, 16, 16]          [2, 128, 16, 16]          256                       --\n",
       "â”‚    â”‚    â””â”€GELU: 3-24                        [2, 128, 16, 16]          [2, 128, 16, 16]          --                        --\n",
       "â”œâ”€ModuleList: 1-7                             --                        --                        (recursive)               --\n",
       "â”‚    â””â”€MaxPoolConv: 2-12                      [2, 128, 16, 16]          [2, 128, 8, 8]            --                        --\n",
       "â”‚    â”‚    â””â”€MaxPool2d: 3-25                   [2, 128, 16, 16]          [2, 128, 8, 8]            --                        2\n",
       "â”‚    â”‚    â””â”€ConvLayer: 3-26                   [2, 128, 8, 8]            [2, 128, 8, 8]            --                        --\n",
       "â”‚    â”‚    â”‚    â””â”€ModuleList: 4-15             --                        --                        --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â””â”€ZeroPad2d: 5-5          [2, 128, 8, 8]            [2, 128, 8, 8]            --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â””â”€Conv2d: 5-6             [2, 128, 8, 8]            [2, 128, 8, 8]            16,512                    [1, 1]\n",
       "â”œâ”€ModuleList: 1-8                             --                        --                        (recursive)               --\n",
       "â”‚    â””â”€ConvLayer: 2-13                        [2, 128, 8, 8]            [2, 256, 8, 8]            --                        --\n",
       "â”‚    â”‚    â””â”€ModuleList: 3-27                  --                        --                        512                       --\n",
       "â”‚    â”‚    â”‚    â””â”€ZeroPad2d: 4-16              [2, 128, 8, 8]            [2, 128, 10, 10]          --                        --\n",
       "â”‚    â”‚    â”‚    â””â”€Conv2d: 4-17                 [2, 128, 10, 10]          [2, 256, 8, 8]            294,912                   [3, 3]\n",
       "â”‚    â”‚    â””â”€LayerNorm2d: 3-28                 [2, 256, 8, 8]            [2, 256, 8, 8]            512                       --\n",
       "â”‚    â”‚    â””â”€GELU: 3-29                        [2, 256, 8, 8]            [2, 256, 8, 8]            --                        --\n",
       "â”‚    â””â”€ConvLayer: 2-14                        [2, 256, 8, 8]            [2, 256, 8, 8]            --                        --\n",
       "â”‚    â”‚    â””â”€ModuleList: 3-30                  --                        --                        512                       --\n",
       "â”‚    â”‚    â”‚    â””â”€ZeroPad2d: 4-18              [2, 256, 8, 8]            [2, 256, 10, 10]          --                        --\n",
       "â”‚    â”‚    â”‚    â””â”€Conv2d: 4-19                 [2, 256, 10, 10]          [2, 256, 8, 8]            589,824                   [3, 3]\n",
       "â”‚    â”‚    â””â”€LayerNorm2d: 3-31                 [2, 256, 8, 8]            [2, 256, 8, 8]            512                       --\n",
       "â”‚    â”‚    â””â”€GELU: 3-32                        [2, 256, 8, 8]            [2, 256, 8, 8]            --                        --\n",
       "â”œâ”€ModuleList: 1-15                            --                        --                        (recursive)               --\n",
       "â”‚    â””â”€InterpolateConvUpSampleLayer: 2-15     [2, 256, 8, 8]            [2, 128, 16, 16]          --                        --\n",
       "â”‚    â”‚    â””â”€ConvLayer: 3-33                   [2, 256, 16, 16]          [2, 128, 16, 16]          --                        --\n",
       "â”‚    â”‚    â”‚    â””â”€ModuleList: 4-20             --                        --                        --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â””â”€ZeroPad2d: 5-7          [2, 256, 16, 16]          [2, 256, 16, 16]          --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â””â”€Conv2d: 5-8             [2, 256, 16, 16]          [2, 128, 16, 16]          32,896                    [1, 1]\n",
       "â”œâ”€ModuleList: 1-16                            --                        --                        (recursive)               --\n",
       "â”‚    â””â”€ConvLayer: 2-16                        [2, 256, 16, 16]          [2, 128, 16, 16]          --                        --\n",
       "â”‚    â”‚    â””â”€ModuleList: 3-34                  --                        --                        --                        --\n",
       "â”‚    â”‚    â”‚    â””â”€ZeroPad2d: 4-21              [2, 256, 16, 16]          [2, 256, 16, 16]          --                        --\n",
       "â”‚    â”‚    â”‚    â””â”€Conv2d: 4-22                 [2, 256, 16, 16]          [2, 128, 16, 16]          32,896                    [1, 1]\n",
       "â”œâ”€ModuleList: 1-17                            --                        --                        (recursive)               --\n",
       "â”‚    â””â”€ConvLayer: 2-17                        [2, 128, 16, 16]          [2, 128, 16, 16]          --                        --\n",
       "â”‚    â”‚    â””â”€ModuleList: 3-35                  --                        --                        256                       --\n",
       "â”‚    â”‚    â”‚    â””â”€ZeroPad2d: 4-23              [2, 128, 16, 16]          [2, 128, 18, 18]          --                        --\n",
       "â”‚    â”‚    â”‚    â””â”€Conv2d: 4-24                 [2, 128, 18, 18]          [2, 128, 16, 16]          147,456                   [3, 3]\n",
       "â”‚    â”‚    â””â”€LayerNorm2d: 3-36                 [2, 128, 16, 16]          [2, 128, 16, 16]          256                       --\n",
       "â”‚    â”‚    â””â”€GELU: 3-37                        [2, 128, 16, 16]          [2, 128, 16, 16]          --                        --\n",
       "â”‚    â””â”€ConvLayer: 2-18                        [2, 128, 16, 16]          [2, 128, 16, 16]          --                        --\n",
       "â”‚    â”‚    â””â”€ModuleList: 3-38                  --                        --                        256                       --\n",
       "â”‚    â”‚    â”‚    â””â”€ZeroPad2d: 4-25              [2, 128, 16, 16]          [2, 128, 18, 18]          --                        --\n",
       "â”‚    â”‚    â”‚    â””â”€Conv2d: 4-26                 [2, 128, 18, 18]          [2, 128, 16, 16]          147,456                   [3, 3]\n",
       "â”‚    â”‚    â””â”€LayerNorm2d: 3-39                 [2, 128, 16, 16]          [2, 128, 16, 16]          256                       --\n",
       "â”‚    â”‚    â””â”€GELU: 3-40                        [2, 128, 16, 16]          [2, 128, 16, 16]          --                        --\n",
       "â”œâ”€ModuleList: 1-15                            --                        --                        (recursive)               --\n",
       "â”‚    â””â”€InterpolateConvUpSampleLayer: 2-19     [2, 128, 16, 16]          [2, 64, 32, 32]           --                        --\n",
       "â”‚    â”‚    â””â”€ConvLayer: 3-41                   [2, 128, 32, 32]          [2, 64, 32, 32]           --                        --\n",
       "â”‚    â”‚    â”‚    â””â”€ModuleList: 4-27             --                        --                        --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â””â”€ZeroPad2d: 5-9          [2, 128, 32, 32]          [2, 128, 32, 32]          --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â””â”€Conv2d: 5-10            [2, 128, 32, 32]          [2, 64, 32, 32]           8,256                     [1, 1]\n",
       "â”œâ”€ModuleList: 1-16                            --                        --                        (recursive)               --\n",
       "â”‚    â””â”€ConvLayer: 2-20                        [2, 128, 32, 32]          [2, 64, 32, 32]           --                        --\n",
       "â”‚    â”‚    â””â”€ModuleList: 3-42                  --                        --                        --                        --\n",
       "â”‚    â”‚    â”‚    â””â”€ZeroPad2d: 4-28              [2, 128, 32, 32]          [2, 128, 32, 32]          --                        --\n",
       "â”‚    â”‚    â”‚    â””â”€Conv2d: 4-29                 [2, 128, 32, 32]          [2, 64, 32, 32]           8,256                     [1, 1]\n",
       "â”œâ”€ModuleList: 1-17                            --                        --                        (recursive)               --\n",
       "â”‚    â””â”€ConvLayer: 2-21                        [2, 64, 32, 32]           [2, 64, 32, 32]           --                        --\n",
       "â”‚    â”‚    â””â”€ModuleList: 3-43                  --                        --                        128                       --\n",
       "â”‚    â”‚    â”‚    â””â”€ZeroPad2d: 4-30              [2, 64, 32, 32]           [2, 64, 34, 34]           --                        --\n",
       "â”‚    â”‚    â”‚    â””â”€Conv2d: 4-31                 [2, 64, 34, 34]           [2, 64, 32, 32]           36,864                    [3, 3]\n",
       "â”‚    â”‚    â””â”€LayerNorm2d: 3-44                 [2, 64, 32, 32]           [2, 64, 32, 32]           128                       --\n",
       "â”‚    â”‚    â””â”€GELU: 3-45                        [2, 64, 32, 32]           [2, 64, 32, 32]           --                        --\n",
       "â”‚    â””â”€ConvLayer: 2-22                        [2, 64, 32, 32]           [2, 64, 32, 32]           --                        --\n",
       "â”‚    â”‚    â””â”€ModuleList: 3-46                  --                        --                        128                       --\n",
       "â”‚    â”‚    â”‚    â””â”€ZeroPad2d: 4-32              [2, 64, 32, 32]           [2, 64, 34, 34]           --                        --\n",
       "â”‚    â”‚    â”‚    â””â”€Conv2d: 4-33                 [2, 64, 34, 34]           [2, 64, 32, 32]           36,864                    [3, 3]\n",
       "â”‚    â”‚    â””â”€LayerNorm2d: 3-47                 [2, 64, 32, 32]           [2, 64, 32, 32]           128                       --\n",
       "â”‚    â”‚    â””â”€GELU: 3-48                        [2, 64, 32, 32]           [2, 64, 32, 32]           --                        --\n",
       "â”œâ”€ModuleList: 1-15                            --                        --                        (recursive)               --\n",
       "â”‚    â””â”€InterpolateConvUpSampleLayer: 2-23     [2, 64, 32, 32]           [2, 32, 64, 64]           --                        --\n",
       "â”‚    â”‚    â””â”€ConvLayer: 3-49                   [2, 64, 64, 64]           [2, 32, 64, 64]           --                        --\n",
       "â”‚    â”‚    â”‚    â””â”€ModuleList: 4-34             --                        --                        --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â””â”€ZeroPad2d: 5-11         [2, 64, 64, 64]           [2, 64, 64, 64]           --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â””â”€Conv2d: 5-12            [2, 64, 64, 64]           [2, 32, 64, 64]           2,080                     [1, 1]\n",
       "â”œâ”€ModuleList: 1-16                            --                        --                        (recursive)               --\n",
       "â”‚    â””â”€ConvLayer: 2-24                        [2, 64, 64, 64]           [2, 32, 64, 64]           --                        --\n",
       "â”‚    â”‚    â””â”€ModuleList: 3-50                  --                        --                        --                        --\n",
       "â”‚    â”‚    â”‚    â””â”€ZeroPad2d: 4-35              [2, 64, 64, 64]           [2, 64, 64, 64]           --                        --\n",
       "â”‚    â”‚    â”‚    â””â”€Conv2d: 4-36                 [2, 64, 64, 64]           [2, 32, 64, 64]           2,080                     [1, 1]\n",
       "â”œâ”€ModuleList: 1-17                            --                        --                        (recursive)               --\n",
       "â”‚    â””â”€ConvLayer: 2-25                        [2, 32, 64, 64]           [2, 32, 64, 64]           --                        --\n",
       "â”‚    â”‚    â””â”€ModuleList: 3-51                  --                        --                        64                        --\n",
       "â”‚    â”‚    â”‚    â””â”€ZeroPad2d: 4-37              [2, 32, 64, 64]           [2, 32, 66, 66]           --                        --\n",
       "â”‚    â”‚    â”‚    â””â”€Conv2d: 4-38                 [2, 32, 66, 66]           [2, 32, 64, 64]           9,216                     [3, 3]\n",
       "â”‚    â”‚    â””â”€LayerNorm2d: 3-52                 [2, 32, 64, 64]           [2, 32, 64, 64]           64                        --\n",
       "â”‚    â”‚    â””â”€GELU: 3-53                        [2, 32, 64, 64]           [2, 32, 64, 64]           --                        --\n",
       "â”‚    â””â”€ConvLayer: 2-26                        [2, 32, 64, 64]           [2, 32, 64, 64]           --                        --\n",
       "â”‚    â”‚    â””â”€ModuleList: 3-54                  --                        --                        64                        --\n",
       "â”‚    â”‚    â”‚    â””â”€ZeroPad2d: 4-39              [2, 32, 64, 64]           [2, 32, 66, 66]           --                        --\n",
       "â”‚    â”‚    â”‚    â””â”€Conv2d: 4-40                 [2, 32, 66, 66]           [2, 32, 64, 64]           9,216                     [3, 3]\n",
       "â”‚    â”‚    â””â”€LayerNorm2d: 3-55                 [2, 32, 64, 64]           [2, 32, 64, 64]           64                        --\n",
       "â”‚    â”‚    â””â”€GELU: 3-56                        [2, 32, 64, 64]           [2, 32, 64, 64]           --                        --\n",
       "â”œâ”€ModuleList: 1-18                            --                        --                        --                        --\n",
       "â”‚    â””â”€InterpolateConvUpSampleLayer: 2-27     [2, 32, 64, 64]           [2, 32, 128, 128]         --                        --\n",
       "â”‚    â”‚    â””â”€ConvLayer: 3-57                   [2, 32, 128, 128]         [2, 32, 128, 128]         --                        --\n",
       "â”‚    â”‚    â”‚    â””â”€ModuleList: 4-41             --                        --                        --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â””â”€ZeroPad2d: 5-13         [2, 32, 128, 128]         [2, 32, 128, 128]         --                        --\n",
       "â”‚    â”‚    â”‚    â”‚    â””â”€Conv2d: 5-14            [2, 32, 128, 128]         [2, 32, 128, 128]         1,056                     [1, 1]\n",
       "â”‚    â””â”€ConvLayer: 2-28                        [2, 32, 128, 128]         [2, 1, 128, 128]          --                        --\n",
       "â”‚    â”‚    â””â”€ModuleList: 3-58                  --                        --                        --                        --\n",
       "â”‚    â”‚    â”‚    â””â”€ZeroPad2d: 4-42              [2, 32, 128, 128]         [2, 32, 128, 128]         --                        --\n",
       "â”‚    â”‚    â”‚    â””â”€Conv2d: 4-43                 [2, 32, 128, 128]         [2, 1, 128, 128]          32                        [1, 1]\n",
       "=================================================================================================================================================\n",
       "Total params: 1,682,048\n",
       "Trainable params: 1,682,048\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 1.09\n",
       "=================================================================================================================================================\n",
       "Input size (MB): 0.13\n",
       "Forward/backward pass size (MB): 51.51\n",
       "Params size (MB): 6.72\n",
       "Estimated Total Size (MB): 58.36\n",
       "================================================================================================================================================="
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(\n",
    "    unetmodel, input_size=(2, 1, 128, 128), depth=8, col_names=[\"input_size\", \"output_size\", \"num_params\", \"kernel_size\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd1a4a16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 32, 64, 64])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block(1,32,stride=2)(torch.rand(2,1,128,128)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864df725",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
